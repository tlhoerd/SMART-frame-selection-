{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "from torch.utils.data import dataloader\n",
    "from torch.multiprocessing import reductions\n",
    "from multiprocessing.reduction import ForkingPickler\n",
    " \n",
    "default_collate_func = dataloader.default_collate\n",
    " \n",
    " \n",
    "def default_collate_override(batch):\n",
    "  dataloader._use_shared_memory = False\n",
    "  return default_collate_func(batch)\n",
    " \n",
    "setattr(dataloader, 'default_collate', default_collate_override)\n",
    " \n",
    "for t in torch._storage_classes:\n",
    "  if sys.version_info[0] == 2:\n",
    "    if t in ForkingPickler.dispatch:\n",
    "        del ForkingPickler.dispatch[t]\n",
    "  else:\n",
    "    if t in ForkingPickler._extra_reducers:\n",
    "         del ForkingPickler._extra_reducers[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda:0 device.\n",
      "100 videos were found in the dataset.\n",
      "there are 13436 frames will be scored\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 896/896 [02:09<00:00,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on these frames: 0.9999\n",
      "[0.9997, 0.9998, 0.9996, 0.9997, 0.9998, 0.9997, 0.9997, 0.9995, 0.9996, 0.9997]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm  \n",
    "import os\n",
    "import json\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from utils_for_picture import read_split_data\n",
    "from my_dataset import MyDataSet\n",
    "    \n",
    "    \n",
    "class ResNet152(nn.Module):\n",
    "    def __init__(self, num_classes = 10):\n",
    "        super(ResNet152, self).__init__()\n",
    "        self.resnet = torchvision.models.resnet152(pretrained = False)\n",
    "        layers = list(self.resnet.children())\n",
    "        \n",
    "        self.layer = nn.Sequential(*layers[:8])\n",
    "        self.out = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten())\n",
    "        self.classifier = nn.Linear(2048, num_classes)\n",
    "\n",
    "                                        \n",
    "    def forward(self, x):      \n",
    "        x = self.layer(x)\n",
    "        x = self.out(x)\n",
    "        p = self.classifier(x)\n",
    "        \n",
    "        return p\n",
    "    \n",
    "\n",
    "def change_lr(net, lr, gamma = 0.8):\n",
    "    if lr >= 0.0000001:\n",
    "        lr = gamma * lr\n",
    "    return lr, optim.Adam(net.parameters(), lr = lr, weight_decay = 0.0001)\n",
    "        \n",
    "\n",
    "def main():\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"using {} device.\".format(device))\n",
    "\n",
    "    data_transform = {\n",
    "        \"train\": transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                     transforms.RandomHorizontalFlip(),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "        \n",
    "        \"val\": transforms.Compose([transforms.Resize(224),\n",
    "                                   #transforms.CenterCrop(224),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])}\n",
    "\n",
    "    image_path = \"./data\"\n",
    "\n",
    "    train_images_path, train_images_label, val_images_path, val_images_label = read_split_data(\"./UCF-101-frame\")\n",
    "\n",
    "    train_dataset = MyDataSet(images_path=train_images_path,\n",
    "                              images_class=train_images_label,\n",
    "                              transform=data_transform[\"train\"])\n",
    "\n",
    "    # 实例化验证数据集\n",
    "    val_dataset = MyDataSet(images_path=val_images_path,\n",
    "                            images_class=val_images_label,\n",
    "                            transform=data_transform[\"val\"])\n",
    "    \n",
    "    batch_size = 15\n",
    "    nw = 0\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=batch_size, shuffle=True,\n",
    "                                               num_workers=nw)\n",
    "\n",
    "\n",
    "    validate_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                                  batch_size=batch_size, shuffle=False,\n",
    "                                                  num_workers=nw)\n",
    "    \n",
    "    train_num = len(train_dataset)\n",
    "    val_num = len(val_dataset)\n",
    "    print(\"using {} images for training, {} images for validation.\".format(train_num,\n",
    "                                                                           val_num))\n",
    "\n",
    "    model_name = \"single_frame_selection_picture\"\n",
    "    net = ResNet152().to(device)\n",
    "    model_weight_path = \"./single_frame_selection_picture.pth\"\n",
    "    assert os.path.exists(model_weight_path), \"file {} dose not exist.\".format(model_weight_path)\n",
    "    net.load_state_dict(torch.load(model_weight_path, map_location=device))\n",
    "    \n",
    "    net.eval()\n",
    "    acc = 0.0  # accumulate accurate number / epoch  \n",
    "    with torch.no_grad():\n",
    "        train_bar = tqdm(train_loader)\n",
    "        for train_data in train_bar:\n",
    "            train_images, train_labels = train_data\n",
    "            outputs = net(train_images.to(device))\n",
    "            predict_y = torch.max(outputs, dim=1)[1]\n",
    "            acc += torch.eq(predict_y, train_labels.to(device)).sum().item()\n",
    "        train_accurate = acc / train_num\n",
    "\n",
    "        acc = 0\n",
    "        val_bar = tqdm(validate_loader)\n",
    "        for val_data in val_bar:\n",
    "            val_images, val_labels = val_data\n",
    "            outputs = net(val_images.to(device))\n",
    "            predict_y = torch.max(outputs, dim=1)[1]\n",
    "            acc += torch.eq(predict_y, val_labels.to(device)).sum().item()\n",
    "        val_accurate = acc / val_num\n",
    "    print('train_accuracy: %.4f' % (train_accurate))\n",
    "    print('val_accuracy: %.4f' % (val_accurate))\n",
    "\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "    epochs = 100\n",
    "    best_acc = 0.0\n",
    "    save_path = './{}.pth'.format(model_name)\n",
    "    train_steps = len(train_loader)   \n",
    "\n",
    "    \n",
    "    lr = 0.0003\n",
    "    jsq = 0\n",
    "    optimizer = optim.Adam(net.parameters(), lr = lr, weight_decay = 0.0001)\n",
    "                       \n",
    "    for epoch in range(epochs):\n",
    "        # train\n",
    "        net.train()\n",
    "        if(jsq == 5):\n",
    "            jsq = 0\n",
    "            lr, optimizer = change_lr(net, lr)\n",
    "            print(f\"the lr from epoch{epoch} is {lr}\")\n",
    "        running_loss = 0.0\n",
    "        train_bar = tqdm(train_loader)\n",
    "        for step, data in enumerate(train_bar):\n",
    "            images, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            p = net(images.to(device))\n",
    "            loss = loss_function(p, labels.to(device))\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            train_bar.desc = \"train epoch[{}/{}] loss:{:.4f}\".format(epoch + 1, epochs, loss)\n",
    "\n",
    "        # validate\n",
    "        net.eval()\n",
    "        acc = 0.0  # accumulate accurate number / epoch\n",
    "        with torch.no_grad():\n",
    "            val_bar = tqdm(validate_loader)\n",
    "            for val_data in val_bar:\n",
    "                val_images, val_labels = val_data\n",
    "                outputs = net(val_images.to(device))\n",
    "                predict_y = torch.max(outputs, dim=1)[1]\n",
    "                acc += torch.eq(predict_y, val_labels.to(device)).sum().item()\n",
    "\n",
    "                val_bar.desc = \"valid epoch[{}/{}]\".format(epoch + 1, epochs)\n",
    "\n",
    "        val_accurate = acc / val_num\n",
    "        print('[epoch %d] train_loss: %.4f  val_accuracy: %.4f' %\n",
    "              (epoch + 1, running_loss / train_steps, val_accurate))\n",
    "\n",
    "        if val_accurate > best_acc:\n",
    "            best_acc = val_accurate\n",
    "            jsq = 0\n",
    "            torch.save(net.state_dict(), save_path)\n",
    "            print(\"  Parameters have been stored\")\n",
    "            \n",
    "        else:\n",
    "            jsq += 1\n",
    "            \n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "    \n",
    "#用于给所有的frame打分时读取数据\n",
    "def score(root):\n",
    "    debug = 0\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"using {} device.\".format(device))\n",
    "    \n",
    "    transform = transforms.Compose([transforms.Resize(224),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "      \n",
    "    train_images_path, train_images_label, val_images_path, val_images_label = read_split_data(\"./UCF-101-frame\", val_rate = 1)\n",
    "\n",
    "    # 实例化验证数据集\n",
    "    dataset = MyDataSet(images_path=val_images_path,\n",
    "                            images_class=val_images_label,\n",
    "                            transform=transform)\n",
    "    \n",
    "    batch_size = 15\n",
    "    nw = 0\n",
    "    data_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                                  batch_size=batch_size, shuffle=False,\n",
    "                                                  num_workers=nw)\n",
    "    \n",
    "    img_num = len(dataset)\n",
    "    print(f\"there are {img_num} frames will be scored\")\n",
    "\n",
    "    net = ResNet152().to(device)\n",
    "    model_weight_path = \"./single_frame_selection_picture.pth\"\n",
    "    assert os.path.exists(model_weight_path), \"file {} dose not exist.\".format(model_weight_path)\n",
    "    net.load_state_dict(torch.load(model_weight_path, map_location=device))\n",
    "    \n",
    "    net.eval()\n",
    "    acc = 0.0  # accumulate accurate number / epoch  \n",
    "    sigmoid = nn.Sigmoid()\n",
    "    scores=[]\n",
    "    with torch.no_grad():\n",
    "        bar = tqdm(data_loader)\n",
    "        for data in bar:\n",
    "            images, labels = data\n",
    "            outputs =sigmoid(net(images.to(device)))\n",
    "            i = 0\n",
    "            for pre in outputs:  \n",
    "                score = pre[labels[i]]\n",
    "                scores.append(round(score.item(), 5))#保留小数点后5位\n",
    "                i += 1\n",
    "            predict_y = torch.max(outputs, dim=1)[1]\n",
    "            acc += torch.eq(predict_y, labels.to(device)).sum().item()\n",
    "        accurate = acc / img_num\n",
    "    print('accuracy on these frames: %.4f' % (accurate))\n",
    "\n",
    "    #scroces是一维的，因为没有打乱顺序，所以顺序上是一一对应的\n",
    "    return scores\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #是否预训练\n",
    "    pretrain = False\n",
    "    if pretrain:\n",
    "        main()\n",
    "    else:\n",
    "        scores = score(\"./UCF-101-frame\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在视频维度上划分训练集与测试集\n",
    "train_accuracy: 0.9738\n",
    "val_accuracy: 0.8247"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在图片维度上划分训练集与测试集\n",
    "train_accuracy: 0.9874 val_accuracy: 0.9996"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    acc = 0.0  # accumulate accurate number / epoch  \n",
    "    with torch.no_grad():\n",
    "        train_bar = tqdm(dataloader)\n",
    "        for train_data in train_bar:\n",
    "            train_images, train_labels = train_data\n",
    "            outputs = net(train_images.to(device))\n",
    "            predict_y = torch.max(outputs, dim=1)[1]\n",
    "            acc += torch.eq(predict_y, train_labels.to(device)).sum().item()\n",
    "            train_accurate = acc / num_img\n",
    "    print('train_accuracy: %.4f' % (train_accurate))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
